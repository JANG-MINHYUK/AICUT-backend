import torch
import torch.nn.functional as F
import numpy as np
import cv2
from moviepy.editor import VideoFileClip
import os
import gc

# ê¸€ë¡œë²Œ ëª¨ë¸ 1ë²ˆë§Œ ë¡œë“œ
model = torch.hub.load('PeterL1n/RobustVideoMatting', 'mobilenetv3')
model = model.cuda() if torch.cuda.is_available() else model
model.eval()

class BackgroundRemover:
    def __init__(self):
        self.model = model

    def process_frame(self, frame):
        print("ğŸ“¸ í”„ë ˆì„ ì²˜ë¦¬ ì‹œì‘")
        try:
            original_h, original_w = frame.shape[:2]
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            resized = cv2.resize(frame_rgb, (192, 192))

            tensor = torch.from_numpy(resized).permute(2, 0, 1).unsqueeze(0).float() / 255.0

            if torch.cuda.is_available():
                tensor = tensor.cuda()

            with torch.no_grad():
                _, pha, *_ = self.model(tensor)
                alpha = F.interpolate(pha, size=(original_h, original_w), mode='bilinear', align_corners=False)
                alpha = alpha.squeeze().cpu().numpy()

            print(f"âœ… alpha ìƒì„± ì™„ë£Œ, ë°˜í™˜ shape: {alpha.shape}")
            return alpha

        except Exception as e:
            print(f"âŒ í”„ë ˆì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None

    def remove_background(self, video_path):
        print("ğŸï¸ ë¹„ë””ì˜¤ ë°°ê²½ ì œê±° ì‹œì‘")
        video = VideoFileClip(video_path)
        fps = video.fps

        output_path = os.path.splitext(video_path)[0] + '_nobg.mp4'
        temp_dir = 'temp_frames'
        os.makedirs(temp_dir, exist_ok=True)

        processed_frames = []

        for i, frame in enumerate(video.iter_frames()):
            print(f"ğŸï¸ í”„ë ˆì„ {i} ìˆ˜ì‹ ë¨, shape: {frame.shape}")
            try:
                alpha = self.process_frame(frame)
                if alpha is None or not isinstance(alpha, np.ndarray):
                    print(f"âš ï¸ í”„ë ˆì„ {i} ì²˜ë¦¬ ì‹¤íŒ¨, alpha ìœ íš¨ì„± ê²€ì‚¬ ì‹¤íŒ¨")
                    continue

                frame_bgra = cv2.cvtColor(frame, cv2.COLOR_RGB2BGRA)
                frame_bgra[:, :, 3] = (alpha * 255).astype(np.uint8)

                frame_path = os.path.join(temp_dir, f'frame_{i:04d}.png')
                cv2.imwrite(frame_path, frame_bgra)
                processed_frames.append(frame_path)

                print(f"âœ… í”„ë ˆì„ {i} ì²˜ë¦¬ ì™„ë£Œ")

                # ë©”ëª¨ë¦¬ í•´ì œ
                torch.cuda.empty_cache()
                gc.collect()

            except Exception as e:
                print(f"â— í”„ë ˆì„ {i} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue

        if not processed_frames:
            raise RuntimeError("âš ï¸ ì²˜ë¦¬ëœ í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤.")

        # ì˜ìƒ ì €ì¥ (ì•ŒíŒŒ ì±„ë„ ì œê±°, ë°°ê²½ í°ìƒ‰ìœ¼ë¡œ ì„¤ì •)
        frame_sample = cv2.imread(processed_frames[0], cv2.IMREAD_UNCHANGED)
        height, width = frame_sample.shape[:2]

        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

        for frame_path in processed_frames:
            frame = cv2.imread(frame_path, cv2.IMREAD_UNCHANGED)
            # ì•ŒíŒŒ ì±„ë„ ì œê±° (í°ìƒ‰ ë°°ê²½ìœ¼ë¡œ í•©ì„±)
            if frame.shape[2] == 4:
                alpha_channel = frame[:, :, 3] / 255.0
                background = np.ones_like(frame[:, :, :3], dtype=np.uint8) * 255  # í°ìƒ‰ ë°°ê²½
                frame_rgb = (frame[:, :, :3] * alpha_channel[..., None] + background * (1 - alpha_channel[..., None])).astype(np.uint8)
            else:
                frame_rgb = frame[:, :, :3]

            out.write(frame_rgb)

        out.release()

        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        for frame_path in processed_frames:
            os.remove(frame_path)
        os.rmdir(temp_dir)

        return output_path

# ì™¸ë¶€ ì‚¬ìš©ìš©
remover_instance = BackgroundRemover()

def remove_background(video_path):
    return remover_instance.remove_background(video_path)
